# Organ
A [Hammond](https://en.wikipedia.org/wiki/Hammond_organ)-like organ project for [JUCE](https://juce.com/) and [AudioKit](https://audiokit.io/).

## The story
This entire repo is the latest step in a long process to expand the [AudioKit Core](https://github.com/AudioKit/AudioKit/tree/master/AudioKit/Core/AudioKitCore). The *Core* initiative itself was primarily aimed at making at least some of AudioKit's underlying C/C\++ code platform-independent, and in that it has been successful. Most of what was done in *Core* was aimed at creating *complete functional blocks* (Nodes) for use in AudioKit/Swift programs. The *AKSampler* instrument and *AKChorus/AKFlanger* effects were the most successful outcomes.

However, when I started trying to create a polysynth by combining elements from the *Core* C\++ code, in the same way I had done for *AKSampler*, I quickly realized the approach was doomed. Any given audio application would be likely to need its own very specific combination of C/C\++ code elements, connected in very specific ways, so it would be senseless to try to create every conceivable combination in advance, as a complete AudioKit Node. Instead, we needed to devise a semi-standard approach whereby any programmer with the requisite basic skills could develop their own DSP code and integrate it into Swift programs, side-by-side with the AudioKit framework itself. This code and repo is what has emerged from this experience.

While working on C\++ wavetable oscillator code, I developed a class called *EnsembleOscillator*, which uses multiple readout phases with detuning and pan-spread to create a chorused "supersaw"-type sound, similar to what Xfer Records' [Serum](https://xferrecords.com/products/serum) and Native Instruments' [Massive](https://www.native-instruments.com/en/products/komplete/synths/massive/) can do. Just for fun, I then made a variation of this called *DrawbarsOscillator*, where the 16 readout phases didn't sound in unison (same pitch, perhaps with a bit of detuning), but instead at multiples of the base note frequency, as in a harmonic series. I chose the name because the resulting sound would be somewhat similar to that of a drawbar-style organ. *DrawbarsOscillator* and its associated C\++ classes were already in *AudioKitCore*, but there was no way to make use of these classes in a Swift program, so I decided this could be the basis of a good "extending AudioKit" code example.

## AudioKit required
**Important:** All the projects included here assume that you clone this repo to your computer so its top-level folder (the one called *Organ*) is a *sibling* to the top-level AudioKit folder (*AudioKit*) on your computer. You **must** clone both this repo and the [AudioKit repo](https://github.com/AudioKit/AudioKit) to be able to build these projects. **Furthermore**, you may have to check out the *develop* branch of AudioKit, which is what I used in creating these projects. Finally, note that AudioKit (especially the develop branch) is under ongoing, active development, and so it is possible these projects may not build correctly for you. If that happens, please **report this on this repo's Issues tab**.

## JUCE version
I'm not going to go even try to teach you about [JUCE](https://juce.com/) here; you're on your own. One thing you should understand is that although JUCE is a commercial code framework, it is *dual-licensed* so it can be used in open-source projects under the [GPL3](https://www.gnu.org/licenses/gpl-3.0.en.html), which, unlike its predecessor the [GPL2](https://www.gnu.org/licenses/gpl-2.0.html), clearly states that GPL3-licensed code may be used together with code licensed under a more permissive license (e.g. the [MIT License](https://opensource.org/licenses/MIT), which governs most of the code here, and all of AudioKit), in a combined open-source work, without the other code automatically becoming subject to the GPL. *Should you choose to use JUCE yourself*, you have two choices: either *publish all of your source code under GPL3* (and mark any more-permissively licensed additions, as I have done here), OR keep your code private and [pay the JUCE license fees](https://shop.juce.com/get-juce).

I haven't included any of the JUCE framework code here, or even tried to link to it as a GitHub subproject. It's better that you install JUCE in the recommended way on your own computer, and then use the included [Projucer](https://docs.juce.com/master/tutorial_new_projucer_project.html) program to open the file *Organ.jucer* in this folder, and use it to generate read-to-build projects for your favorite IDE. These projects will incorporate all of the files in the *Source* folder, as well as those in the *Common* folder one level up, and several folders inside the *Core* subtree of the main AudioKit repo (which is why it says above that you must clone both repos, to sibling folders).

The basic polyphonic organ instrument is defined by the *OrganVoice* and *Organ* classes. *OrganVoice* inherits from a new class called *VoiceBase* in the *Common* folder, which together with the associated class *VoiceManager*, abstracts most of the voice-management functionality I originally wrote for *AKSampler*, so it can be used for any polysynth instrument. *OrganVoice* is very simple; it just contains a single *DrawbarsOscillator* and an *ADSREnvelope* (both defined in AudioKit Core). The envelopes are only used to soften the attack and release slightly, to avoid clicking.

The *Organ* class mainly provides access to standard parameters like tuning ratio (used to transpose the whole instrument down an octave, like the Hammond), but also provides a set of nine "drawbar" settings, which are simply 9 of the 16 partials available in *DrawbarsOscillator*, mapped onto the index values 0 through 8, to correspond with the [drawbars on a Hammond](https://en.wikipedia.org/wiki/Hammond_organ#/media/File:Hammond-drawbars-plain.svg).

The class *Distortion* implements a very simple wave shaper (based on *FunctionTable* defined in Core) using a power-curve. Increasing the "power" parameter increases the exponent of the power curve, making it more nonlinear and hence adding distortion.

For simplicity, I brought the *Organ*, *Distortion*, and *Leslie* classes together in the *MyOrganAudioProcessor* class, which is the standard DSP-object class generated by the JUCE *Projucer*. I didn't attempt to do any clever parameter-handling (aka DAW automation) in that class, because my only goal was to test the underlying DSP code, and to do that I could just make a simple GUI in the *MyOrganAudioProcessorEditor* class and have it operate directly on the DSP parameters.

The only tricky aspect to integrating the *Organ*, *Distortion*, and *Leslie* classes was the need to provide an intermediate stereo audio buffer, to hold the output of the *Organ* code, before passing on to the *Leslie* code. (A second buffer between *Organ* and *Distortion* is not needed, because the *Distortion* effect has no memory and can process samples one at a time in-place in the work buffer.) Because the size of the required buffer is not known until the *init()* function is called at run-time, the necessary memory must be allocated dynamically and freed when necessary.

Note the JUCE project also links to the *kissfft* subfolder in the *Core/Soundpipe/lib* folder inside AudioKit, because that's needed to fully compile *WaveStack*, upon which *DrawbarsOscillator* depends. Several other files which appear in the JUCE projects are also included for similar reasons.

## AudioKit version
As of this writing, there is only a macOS version of the AudioKit organ app. I hope to add an iOS version soon. Only the GUI code will differ; the DSP code will be identical.

The first step in building the AudioKit version was to create a new Xcode project according to the steps described for [extending AudioKit](https://github.com/AudioKit/AudioKit/tree/master/Developer/macOS/ExtendingAudioKit) in the main AudioKit repo. I chose to link to the pre-compiled AudioKit frameworks, rather than including the macOS AudioKit Xcode project as a sub-project, because the DSP code was already tested and I didn't expect to have to do a lot of complex debugging.

I then added a *conductor.swift* file and MIDI handling code adapted from the [AudioKit Sampler Demo](https://github.com/AudioKit/SamplerDemo), to flesh out a basic polysynth app. I found it very useful to include an *AKNodeOutputPlot* in the main storyboard, so I could visualize what the audio code produces. (Early on, this allowed me to notice a flaw in the *FunctionTable::triangle()* implementation, which resulted in a DC bias on the generated triangle waves which are used by *DrawbarsOrgan*.)

The next step was to add the wrapper classes *AKOrganDSP*, *AKOrganAudioUnit*, and *AKOrgan* as described in the main README for this repo (one level up). For this I used the *Python wrapper generator* code. I generated the wrapper classes repeatedly, adding parameters each time until I had exposed as many as were needed.

While working on the wrapper classes, I realized that the approach I had used in the JUCE version, for integrating the *Organ*, *Distortion*, and *Leslie* objects wasn't quite adequate for the AudioKit version. At first I planned to integrate these in the *AKOrganDSP* class (as I had done in *MyOrganAudioProcessor* in the JUCE version), but I realized that this would mean my templates wouldn't be adequate. The *AKDSP* templates define the *AKOrganDSP* class as *inheriting* from the *Organ* class, so I had to integrate the *Distortion* and *Leslie* objects in that class. As a result, the C\++ *Organ* class here is more elaborate than the one in the JUCE version.

An **important thing to understand** about the *AKOrganDSP* class is that, because it's an Objective-C class which will be [bridged to Swift](https://developer.apple.com/documentation/swift/imported_c_and_objective-c_apis/importing_objective-c_into_swift), it **cannot expose any complex object types in the header**. This is the reason for the slightly strange *InternalData* struct declaration. In *AKOrganDSP.hpp*, it is only necessary to expose a **void\*** *pointer* to such a struct (actually a *std::unique_ptr*); the details of the struct itself are defined only in *AKOrganDSP.cpp*, which is not seen by the Swift/Objective-C bridging system in Xcode. (The *AKOrgan-Bridging-Header.h* file #include's only the *AKOrganDSP.hpp* file.) Similar coding patterns are used in many AudioKit Core classes.

This hidden *InternalData* struct proved useful in integrating *Distortion* and *Leslie* instances into the *AKOrgan* class. It was also the obvious place to declare the work buffer, and this yielded a pleasant surprise: I was all set to do the dynamic-allocation stuff I had to do for the JUCE version, until I remembered that the *AKOrganDSP::process()* function never asks *Organ::render()* for more than 16 samples at a time, so I could simply declare two 16-sample arrays *leftWorkBuffer[]* and *rightWorkBuffer[]* in the *Organ::InternalData* struct.

In hindsight, I realize I was foolish to put off the integration of *Organ*, *Distortion*, and *Leslie*. I got away with it this time (debugging the AudioKit version of the Organ program turned out to be pretty simple), but my lesson for the future is clear: The *AKDSP* templates are designed to wrap a *single* C\++ class which the *AKDSPBase*-derived class inherits from, so any integration of other C\++ objects should be done in that class, and tested (e.g. with JUCE) *before* attempting to build the Objective-C/Swift wrappers.
